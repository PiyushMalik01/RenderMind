# RenderMind Copilot

AI-powered Blender assistant with local fine-tuned model support and web-based interface.

## ğŸ—ï¸ Project Structure

```
rendermind_copilot/
â”œâ”€ .env                            # Environment variables (API keys, model paths)
â”œâ”€ requirements.txt                 # Python dependencies
â”œâ”€ README.md
â”œâ”€ models/                          # Fine-tuned model adapters (PEFT/LoRA)
â”‚   â””â”€ codellama_adapter/           # Your adapter files go here
â”‚       â”œâ”€ adapter_model.safetensors
â”‚       â”œâ”€ adapter_config.json
â”‚       â””â”€ tokenizer.json
â”œâ”€ assets/                          # 3D model library
â”‚   â”œâ”€ food/
â”‚   â”‚   â”œâ”€ apple.blend
â”‚   â”‚   â””â”€ pomegranate.blend
â”‚   â””â”€ nature/
â”‚       â””â”€ trees.blend
â”œâ”€ serve/                           # Model serving (Flask API)
â”‚   â”œâ”€ __init__.py
â”‚   â”œâ”€ model_interface.py           # Load base model + adapter with PEFT
â”‚   â”œâ”€ api.py                       # Flask server with /generate endpoint
â”‚   â””â”€ starter.sh                   # Server startup script
â”œâ”€ web_ui/                          # Browser-based chat interface
â”‚   â”œâ”€ index.html
â”‚   â”œâ”€ style.css
â”‚   â””â”€ app.js
â”œâ”€ blender_addon/                   # Blender addon code
â”‚   â”œâ”€ __init__.py
â”‚   â”œâ”€ operators.py                 # Blender operators
â”‚   â”œâ”€ ui_panel_modal.py            # UI panels
â”‚   â”œâ”€ model_library.py             # 3D asset management
â”‚   â”œâ”€ blender_utils.py             # Blender properties & utilities
â”‚   â”œâ”€ client_integration.py        # API client for local model
â”‚   â”œâ”€ plan_emitter.py
â”‚   â””â”€ dev_reload.py
â”œâ”€ tools/                           # Development & testing tools
â”‚   â””â”€ (coming soon)
â””â”€ utils/                           # Shared utilities
    â”œâ”€ __init__.py
    â””â”€ safe_filters.py              # Code safety checks
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Configure Environment

Create `.env` file:
```bash
# OpenAI API (for fallback)
OPENAI_API_KEY=your_key_here

# Local Model Configuration
BASE_MODEL=codellama/CodeLlama-7b-hf
ADAPTER_PATH=./models/codellama_adapter
MODEL_SERVER_URL=http://localhost:5000

# Server Configuration
PORT=5000
```

### 3. Start Model Server (Optional - for local fine-tuned model)

```bash
python -m serve.api
```

This starts a Flask server on port 5000 that serves your fine-tuned model.

### 4. Install Blender Addon

1. Open Blender
2. Edit â†’ Preferences â†’ Add-ons â†’ Install
3. Select this entire folder
4. Enable "RenderMind Copilot (Dev)"

### 5. Use the Web UI

1. In Blender, open RenderMind panel (View3D â†’ Sidebar â†’ RenderMind)
2. Click "Start Web Server"
3. Click "Open Web UI"
4. Start chatting!

## ğŸ“¦ Features

### âœ¨ Web-Based Chat Interface
- Real-time WebSocket communication with Blender
- Voice input via Whisper API
- Auto-execute generated code
- Beautiful dark theme UI

### ğŸ¨ 3D Asset Library
- Automatically imports matching models from `assets/` folder
- Smart keyword matching
- Supports .blend, .fbx, .obj, .gltf, .stl formats

### ğŸ¤– Dual Model Support
1. **OpenAI API** (GPT-4o-mini) - Fast, reliable, cloud-based
2. **Local Fine-Tuned Model** - Your custom CodeLlama adapter

### ğŸ›¡ï¸ Safety Features
- Code validation and sanitization
- Dangerous pattern detection
- Import whitelist

## ğŸ”§ Using Your Fine-Tuned Model

### Setup

1. Place your adapter in `models/codellama_adapter/`
2. Update `.env` with correct paths
3. Start the model server: `python -m serve.api`
4. Update Blender addon to use local model

### Adapter Structure

```
models/codellama_adapter/
â”œâ”€ adapter_model.safetensors     # PEFT/LoRA weights
â”œâ”€ adapter_config.json            # Adapter configuration
â”œâ”€ tokenizer.json                 # Tokenizer files
â””â”€ ...
```

## ğŸ¯ Usage Examples

**Using 3D Assets:**
- "add an apple" â†’ Imports `assets/food/apple.blend`
- "create trees" â†’ Imports `assets/nature/trees.blend`

**Generating Code:**
- "create a red cube" â†’ AI generates code
- "make 10 spheres in a circle" â†’ Procedural generation
- "add a camera looking at origin" â†’ Scene setup

**Voice Input:**
- Click microphone button
- Speak your command
- Automatic transcription via Whisper

## ğŸ§ª Development

### Hot Reload
The addon supports hot reload during development. Changes are automatically detected.

### Testing
```bash
# Test model server
curl http://localhost:5000/health

# Test code generation
curl -X POST http://localhost:5000/generate \
  -H "Content-Type: application/json" \
  -d '{"prompt":"create a cube"}'
```

## ğŸ“ Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENAI_API_KEY` | OpenAI API key | Required for OpenAI mode |
| `BASE_MODEL` | HuggingFace model name | `codellama/CodeLlama-7b-hf` |
| `ADAPTER_PATH` | Path to PEFT adapter | `./models/codellama_adapter` |
| `MODEL_SERVER_URL` | Local model server URL | `http://localhost:5000` |
| `PORT` | Flask server port | `5000` |

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch
3. Make changes
4. Test with Blender
5. Submit pull request

## ğŸ“„ License

MIT License - See LICENSE file for details

## ğŸ™ Credits

- Built with Blender Python API
- Powered by OpenAI GPT-4 & Whisper
- Fine-tuning with PEFT/LoRA
- Base model: CodeLlama-7b

---

**Need help?** Check the issues page or create a new issue.
